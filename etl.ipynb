{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "t1 = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, DateType, TimestampType\n",
    "from pyspark.sql import functions as F \n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added header ['credentials'] on cfg file\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['credentials']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['credentials']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AKIA3XUTSG6HME7UKJ6H'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MIR9oCH7aSPqq1J5hejsmzJi2UdpGyx8eIGlQlDF'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c8fd48da5f50:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f151bd71ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peek at the data on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|     artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARTC1LV1187B9A4858|        51.4536|Goldsmith's Colle...|        -0.01802|  The Bonzo Dog Band|301.40036|        1|SOAFBCP12A8C13CC7D|King Of Scurf (20...|1972|\n",
      "|ARA23XO1187B9AF18F|       40.57885|Carteret, New Jersey|       -74.21956|     The Smithereens|  192.522|        1|SOKTJDS12AF72A25E5|Drown In My Own T...|   0|\n",
      "|ARSVTNL1187B992A91|       51.50632|     London, England|        -0.12714|       Jonathan King|129.85424|        1|SOEKAZG12AB018837E|I'll Slap Your Fa...|2001|\n",
      "|AR73AIO1187B9AD57B|       37.77916|   San Francisco, CA|      -122.42005|   Western Addiction|118.07302|        1|SOQPWCR12A6D4FB2A3|A Poor Recipe For...|2005|\n",
      "|ARXQBR11187B98A2CC|           null|  Liverpool, England|            null|Frankie Goes To H...|821.05424|        1|SOBRKGM12A8C139EF6|Welcome to the Pl...|1985|\n",
      "+------------------+---------------+--------------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_song = spark.read.json('s3a://udacity-dend/song_data/A/A/A/*.json')\n",
    "df_song.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+------------+------+-------------+--------------------+------+\n",
      "| artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|        song|status|           ts|           userAgent|userId|\n",
      "+-------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+------------+------+-------------+--------------------+------+\n",
      "|   null|Logged In|   Walter|     M|            0|    Frye|     null| free|San Francisco-Oak...|   GET|    Home|1.540919166796E12|       38|        null|   200|1541105830796|\"Mozilla/5.0 (Mac...|    39|\n",
      "|   null|Logged In|   Kaylee|     F|            0| Summers|     null| free|Phoenix-Mesa-Scot...|   GET|    Home|1.540344794796E12|      139|        null|   200|1541106106796|\"Mozilla/5.0 (Win...|     8|\n",
      "|Des'ree|Logged In|   Kaylee|     F|            1| Summers|246.30812| free|Phoenix-Mesa-Scot...|   PUT|NextSong|1.540344794796E12|      139|You Gotta Be|   200|1541106106796|\"Mozilla/5.0 (Win...|     8|\n",
      "|   null|Logged In|   Kaylee|     F|            2| Summers|     null| free|Phoenix-Mesa-Scot...|   GET| Upgrade|1.540344794796E12|      139|        null|   200|1541106132796|\"Mozilla/5.0 (Win...|     8|\n",
      "|Mr Oizo|Logged In|   Kaylee|     F|            3| Summers|144.03873| free|Phoenix-Mesa-Scot...|   PUT|NextSong|1.540344794796E12|      139|     Flat 55|   200|1541106352796|\"Mozilla/5.0 (Win...|     8|\n",
      "+-------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log = spark.read.json('s3a://udacity-dend/log_data/2018/11/2018-11-01-events.json')\n",
    "df_log.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sample data in my own S3 bucket to test the script\n",
    "\n",
    "input_data = \"s3a://udacity-dend-michlin0825/\" \n",
    "output_data = \"s3a://sparkify-dend-michlin0825/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filepath to song data file\n",
    "\n",
    "song_data = input_data + 'song_data/*/*/*/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+---------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|               |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "+------------------+---------------+---------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read song data file\n",
    "\n",
    "df_song = spark.read.json(song_data)\n",
    "df_song.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "\n",
    "songs_table = df_song.select([\"title\", \"artist_id\",\"year\", \"duration\"]).dropDuplicates().withColumn(\"song_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----+---------+------------+\n",
      "|               title|         artist_id|year| duration|     song_id|\n",
      "+--------------------+------------------+----+---------+------------+\n",
      "|It Wont Be Christmas|ARMBR4Y1187B9990EB|   0|241.47546|           0|\n",
      "|      Setanta matins|AR5KOSW1187FB35FF4|   0|269.58322| 25769803776|\n",
      "|       City Slickers|AR8IEZO1187B99055E|2008|149.86404| 68719476736|\n",
      "|           Ten Tonne|AR62SOJ1187FB47BB5|2005|337.68444| 94489280512|\n",
      "|     Baby Come To Me|AR9AWNF1187B9AB0B4|   0|236.93016|111669149696|\n",
      "+--------------------+------------------+----+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "\n",
    "songs_table.write.mode('overwrite').partitionBy(\"year\", \"artist_id\").parquet(output_data + 'songs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "\n",
    "artists_table = df_song.selectExpr([\"artist_id\", \"artist_name as name\", \"artist_location as location\", \"artist_latitude as latitude\", \n",
    "                                    \"artist_longitude as longitude\"]).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+--------+----------+\n",
      "|         artist_id|           name|       location|latitude| longitude|\n",
      "+------------------+---------------+---------------+--------+----------+\n",
      "|ARPBNLO1187FB3D52F|       Tiny Tim|   New York, NY|40.71455| -74.00712|\n",
      "|ARXR32B1187FB57099|            Gob|               |    null|      null|\n",
      "|AROGWRA122988FEE45|Christos Dantis|               |    null|      null|\n",
      "|ARBGXIG122988F409D|     Steel Rain|California - SF|37.77916|-122.42005|\n",
      "|AREVWGE1187B9B890A|     Bitter End|      Noci (BA)| -13.442|  -41.9952|\n",
      "+------------------+---------------+---------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "\n",
    "artists_table.write.mode('overwrite').parquet(output_data + 'artists/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filepath to log data file\n",
    "\n",
    "log_data = input_data + 'log-data/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read log data file\n",
    "\n",
    "df_log = spark.read.json(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+-------------+------+-------------+--------------------+------+\n",
      "|  artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|         song|status|           ts|           userAgent|userId|\n",
      "+--------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+-------------+------+-------------+--------------------+------+\n",
      "|Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "+--------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+-------------+------+-------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter by actions for song plays\n",
    "\n",
    "df_log = df_log.filter(df_log.page == 'NextSong')\n",
    "df_log.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns for users table\n",
    "\n",
    "users_table = df_log.select(col('firstName').alias('first_name'), \n",
    "                            col('lastName').alias('last_name'), \n",
    "                            col('gender'), \n",
    "                            col('level'), \n",
    "                            col('userId').alias('user_id')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+-----+-------+\n",
      "|first_name|last_name|gender|level|user_id|\n",
      "+----------+---------+------+-----+-------+\n",
      "|      Ryan|    Smith|     M| free|     26|\n",
      "|    Adelyn|   Jordan|     F| free|      7|\n",
      "|    Ayleen|     Wise|     F| free|     71|\n",
      "|    Sienna|    Colon|     F| free|     81|\n",
      "|    Dustin|      Lee|     M| free|     87|\n",
      "+----------+---------+------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write users table to parquet files\n",
    "\n",
    "users_table.write.mode('overwrite').parquet(output_data + 'users/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create timestamp column from original timestamp column\n",
    "\n",
    "get_timestamp = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000), TimestampType())\n",
    "df_log = df_log.withColumn(\"timestamp\", get_timestamp(df_log.ts))\n",
    "df_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           timestamp|\n",
      "+--------------------+\n",
      "|2018-11-15 00:30:...|\n",
      "|2018-11-15 00:41:...|\n",
      "|2018-11-15 00:45:...|\n",
      "|2018-11-15 03:44:...|\n",
      "|2018-11-15 05:48:...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log[['timestamp']].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create datetime column from original timestamp column\n",
    "\n",
    "df_log = df_log.withColumn('start_time', get_timestamp(df_log.ts))\n",
    "df_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          start_time|\n",
      "+--------------------+\n",
      "|2018-11-15 00:30:...|\n",
      "|2018-11-15 00:41:...|\n",
      "|2018-11-15 00:45:...|\n",
      "|2018-11-15 03:44:...|\n",
      "|2018-11-15 05:48:...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log[['start_time']].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to create time table\n",
    "\n",
    "df_log = df_log.withColumn(\"hour\", F.hour(\"timestamp\"))        \\\n",
    "               .withColumn(\"day\", F.dayofweek(\"timestamp\"))    \\\n",
    "               .withColumn(\"week\", F.weekofyear(\"timestamp\"))  \\\n",
    "               .withColumn(\"month\", F.month(\"timestamp\"))      \\\n",
    "               .withColumn(\"year\", F.year(\"timestamp\"))        \\\n",
    "               .withColumn(\"weekday\", F.dayofweek(\"timestamp\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = df_log.select('start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 00:30:...|   0|  5|  46|   11|2018|      5|\n",
      "|2018-11-15 00:41:...|   0|  5|  46|   11|2018|      5|\n",
      "|2018-11-15 00:45:...|   0|  5|  46|   11|2018|      5|\n",
      "|2018-11-15 03:44:...|   3|  5|  46|   11|2018|      5|\n",
      "|2018-11-15 05:48:...|   5|  5|  46|   11|2018|      5|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # write time table to parquet files\n",
    "\n",
    "time_table.write.mode('overwrite').partitionBy(\"year\", \"month\").parquet(output_data + 'time/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "\n",
    "df_log.createOrReplaceTempView(\"view_log\")\n",
    "\n",
    "df_song = df_song.drop('year')\n",
    "df_song.createOrReplaceTempView(\"view_song\")\n",
    "\n",
    "time_table.createOrReplaceTempView(\"view_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table\n",
    "\n",
    "songplays_table = spark.sql(\n",
    "    \"\"\"select distinct view_log.start_time, view_log.userId as user_id, view_log.level, view_log.sessionId as session_id, \n",
    "    view_log.location, view_log.userAgent as user_agent, view_song.song_id, view_song.artist_id, view_time.year, view_time.month\n",
    "    from view_log\n",
    "        inner join \n",
    "    view_song \n",
    "        on view_log.artist = view_song.artist_name and \n",
    "        view_log.song = view_song.title and\n",
    "        view_log.length = view_song.duration\n",
    "        inner join \n",
    "    view_time \n",
    "        on view_log.start_time = view_time.start_time\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_table = songplays_table.withColumn(\"songplay_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+----------+--------------------+--------------------+------------------+------------------+----+-----+------------+\n",
      "|          start_time|user_id|level|session_id|            location|          user_agent|           song_id|         artist_id|year|month| songplay_id|\n",
      "+--------------------+-------+-----+----------+--------------------+--------------------+------------------+------------------+----+-----+------------+\n",
      "|2018-11-21 21:56:...|     15| paid|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|2018|   11|549755813888|\n",
      "+--------------------+-------+-----+----------+--------------------+--------------------+------------------+------------------+----+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- songplay_id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songplays table to parquet files\n",
    "\n",
    "songplays_table.write.mode('overwrite').partitionBy(\"year\", \"month\").parquet(output_data + 'songplays/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:13:52.432198\n"
     ]
    }
   ],
   "source": [
    "t2 = datetime.datetime.now()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
